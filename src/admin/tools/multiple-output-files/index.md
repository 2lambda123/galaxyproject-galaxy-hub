---
title: Strategies for tools that create more than one output file
---

Tools which create more than one output file are common.  There are several different methods to accommodate this need.  Each one of these has their advantages and weaknesses; careful thought should be employed to determine the best method for a particular tool.

# Static Multiple Outputs

Handling cases when tools create a static number of outputs is simple.  Simply include an <output> tag for each output desired within the tool XML file:

```xml
<tool id="example_tool" name="Multiple output" description="example">
    <command>example_tool.sh $input1 $tool_option1 $output1 $output2</command>
    <inputs>
        ...
    </inputs>
    ...
    <outputs>
        <data format="interval" name="output1" metadata_source="input1" />
        <data format="pdf" name="output2" />
    </outputs>
</tool>
```


# Variable Static Outputs (Determined by Parameter Values)

In cases when the number of output files varies, but can be determined based upon a user's parameter selection, the use of the filter tag can be used.  The text contents of the <filter> tag are **eval**ed and if the expression is True a dataset will be created as normal.  If the expression is False, the output dataset will not be created; instead a NoneDataset object will be created and made available - when used on the command line the text **None** will appear instead of a file path. The local namespace of the filter has been populated with the tool parameters.


```xml
<tool id="example_tool" name="Multiple output" description="example">
    <command>example_tool.sh $input1 $tool_option1 $output1 $output2</command>
    <inputs>
       ...
       <param name="tool_option1" type="select" label="Type of output">
           <option value="1">Single File</option>
           <option value="2">Two Files</option>
       </param>
       <conditional name="condition1">
           <param name="tool_option2" type="select" label="Conditional output">
               <option value="yes">Yes</option>
               <option value="no">No</option>
           </param>
           ...
       </condition>
       ...
    </inputs>
    ...
    <outputs>
        <data format="interval" name="output1" metadata_source="input1" />
        <data format="pdf" name="output2" >
            <filter>tool_option1 == "2"</filter>
        </data>
        <data format="txt" name="output3" >
            <filter>condition1['tool_option2'] == "yes"</filter>
        </data>
    </outputs>
</tool>
```


The command line generated when **tool_option1** is set to **Single File** is:

```
example_tool.sh input1_FILE_PATH 1 output1_FILE_PATH None
```



The command line generated when **tool_option1** is set to **Two Files** is:

```
example_tool.sh input1_FILE_PATH 2 output1_FILE_PATH output2_FILE_PATH
```


The datatype of an output can be determined by conditional parameter settings as in  tools/filter/pasteWrapper.xml

```xml
 <outputs>
   <data format="input" name="out_file1" metadata_source="input1">
     <change_format>
       <when input_dataset="input1" attribute="ext" value="bed" format="interval"/>
     </change_format>
   </data>
 </outputs>
```


## Single HTML Output with Linked Files and Images

There are times when a single history item is desired, but this history item is composed of multiple files which are only useful when considered together. This is done by having a single (**primary**) output and storing additional files in a directory associated with the primary dataset.

A common usage of this strategy is to have the primary dataset be an HTML file and then store additional content (reports, pdfs, images, etc) in the dataset extra files directory. The content of this directory can be referenced using relative links with in the primary HTML file. Clicking on the eye icon to view the dataset will display the HTML page.

In some cases, the tool you are wrapping writes the HTML for you. The fastqc wrapper ([xml](https://github.com/galaxyproject/tools-iuc/blob/ee9c9efdd7c86b08b9d00780778bfc718caa325c/tools/fastqc/rgFastQC.xml), [python](https://github.com/galaxyproject/tools-iuc/blob/ee9c9efdd7c86b08b9d00780778bfc718caa325c/tools/fastqc/rgFastQC.py)) is an example of a tool where the application generates html and image outputs, but these need to be massaged to make them Galaxy friendly. Alternatively, if the underlying tool does not have an html output, you might need to write a wrapper yourself that produces the valid html. In either situation, the html datatype offers a flexible way to display very complex collections of related outputs inside a single history item or to present a complex html page generated by an application.

### Step 1: Configure Output Files

Use the `html` datatype when declaring the outputs in the xml wrapper:

```xml
<outputs>
  <data format="html" name="html_file" label="${tool_name} Report">
</outputs>
```

### Step 2: Configure the Output Directory

In Galaxy, html outputs are stored as the output html file, and a directory containing any resources that should be referenced in that html file. You will need to configure the application to write the associated images or files into that directory. In the command block, this directory is available from the `.files_path` attribute of the dataset:

```xml
<command>myscript.pl "$input1" "$html_file" "$html_file.files_path"</command>
```

`myscript.pl` should then write any images to that folder. That folder may not exist, so your wrapper should generally ensure it exists before attempting to write to it. This can be done with a call to `mkdir`:

```xml
<command>
    mkdir -p "$html_file.files_path";
    myscript.pl "$input1" "$html_file" "$html_file.files_path"
</command>
```

### Step 3: Write Valid HTML

The application must write valid html to the `$html_file` in order to be seen by the user when they view (eye icon) the dataset. All application outputs that will be included as links (image source, a hrefs) in that html code should be placed in the `$html_file.files_path` directory. When generating the html, files that are referenced from the `$html_file.files_path` should be referenced by their name, without any other path decoration. If the following snippet is in the `$html_file` output,

```html
<a href="file1.xls">Some special output</a>
<br/>
<img src="image1.jpg" >
```

Then `file1.xls` and `image1.jpg` should be placed in `$html_file.files_path/file1.xls` and `$html_file.files_path/image1.jpg`, respectively. As mentioned above, FastQC does not references files in the way Galaxy would prefer in its html output. Hence the wrapper must correct the paths within the html in order for it to be compatible with Galaxy.

## Composite Datatypes

html is a subclass of "composite datasets" (a single primary file with additional associated files.) New subclasses of composite can be implemented in order to have more structured outputs (as seen with Rgenetics) but this requires adding the new definition to Galaxy. html files require no extension of the core framework, and may be a simpler option in most cases. For more information visit [Composite Datatypes](/src/admin/datatypes/composite-datatypes/index.md).

# Variable Outputs (Cannot be Computed Before Runtime)

There are times when the number of output datasets varies entirely based upon the inputs and cannot be determined ahead of time. Tools can be configured to "discover" an arbitrary number of files that will be added after the job's completion to the user's history as new datasets. There are a couple of options to handle this special case: dataset collections (workflow compatible), and regular datasets (not workflow compatible.) Whenever possible you should prefer dataset collections or one of the previously mentioned methods, so your tool can be used in workflows.

## Dataset Collections

Discovered Datasets can also be combined with dataset collections as shown in: [Galaxy Tool Generating Dataset Collections](https://web.science.mq.edu.au/~cassidy/2015/10/21/galaxy-tool-generating-datasets/)

While not yet fully documented here, there are extensive [test cases](https://github.com/galaxyproject/galaxy/tree/release_17.01/test/functional/tools) which cover datasets collections. These test cases are generally the best reference for how to create the various types of dataset collections.

## Non-Dataset Collections

Discovering datasets require a fixed 'parent' output dataset - this dataset will act as the reference for our additional datasets. By default, this appears as an empty dataset that is output. Many tool authors choose to use this as a text report or log of the tool run, otherwise users may think that something is wrong when the first dataset is empty.

Discovered datasets require a unique designation (the output dataset name). Your tool should write its output files to the current working directory, or to a subdirectory thereof.

### Examples

Consider a tool that creates some text files *and* some bam files. To allow this tool to work with `discover_datasets`, the tool should be configured to write them to a subdirectory. We have arbitrarily chosen our subdirectory name as `split`, and configured our tool to place its outputs in that folder. During execution, the tool will write the bam and text files into that directory, with the appropriate extension. In our tool XML, we will then configure Galaxy to discover the outputs with the following statement:

```xml
<outputs>
  <data format="txt" name="report">
    <discover_datasets pattern="__designation_and_ext__" directory="split" visible="true" />
  </data>
</outputs>
```

Here, we have a primary output named `report`. By default this is empty, but we could write a short report there to help our users. Within the `report` output, we tell Galaxy to discover some datasets by looking in the `directory` for the `pattern`, and then marking them as `visibile` in the user's history.

If the tool produced the following files when it was run:

- `split/samp1.bam`
- `split/samp2.bam`
- `split/samp3.bam`
- `split/samp4.bam`
- `split/cross1.txt`
- `split/cross2.txt`

Then 6 datasets would be discovered and added to the history. The `<discover_datasets>` block would look in `directory="split"` and find a number of files which all match the generic `pattern="__designation_and_ext__"`. These files would show up in your Galaxy history as `My Tool (Samp1.bam)`, `My Tool (Samp2.bam)`, and so on. Since we have used `__designation_and_ext__`, galaxy will see the `.bam` and `.txt` extensions and set the filetype appropriately.

#### Incorrect Datatype Extension

If for some reason a different or incorrect file extension was used, such as a tool which writes out `.tsv` files, Galaxy would not know how to handle those as tabular datasets. In that case, instead of `__designation_and_ext__`, we can use `__designation__` and the `ext` option:

```xml
<outputs>
  <data format="txt" name="report">
    <discover_datasets pattern="__designation__" ext="tabular" directory="tables" visible="true" />
  </data>
</outputs>
```

In this example, if the tool created 3 tabular files such as `tables/part1.tsv`, `tables/part2.tsv`, and `tables/part3.tsv` - then 3 datasets will be discovered, all with the type `tabular` and with dataset names like `My Tool (part1.tsv)`, `My Tool (part2.tsv)`, and `My Tool (part3.tsv)`.

#### Customizing the Name

If you do not want `My Tool (...)` to be part of the history dataset name, you can replace `designation` with `name`. So `__designation_and_ext__` would be replaced by `__name_and_ext__` and `__designation__` would be replaced by `__name__`.

#### Hiding the Extension

It may not be desirable for the extension (`.tsv`) to appear in the `designation` this way. These patterns `__designation__` and  `__designation_and_ext__` can be replaced with regular expressions that capture metadata from the file name using named groups. `__designation__` and `__designation_and_ext__` are just shortcuts, for `(?P<designation>.*)` and  `(?P<designation>.*)\.(?P<ext>[^\._]+)?`, respectively. If you need, you can override these by manually specifying the regular expressions using the `pattern` optin in your `discover_datasets` block. The above example can be modified as:

```xml
<outputs>
  <data format="txt" name="report">
    <discover_datasets pattern="(?P&lt;designation&gt;.+)\.tsv" ext="tabular" directory="tables" visible="true" />
  </data>
</outputs>
```

Going back to our `tables/part{1,2,3}.tsv` example, all three datasets are still be captured but this time with designations of `part1`, `part2`, and `part3`.

Notice here the `<` and `>` in the tool pattern had to be replaced with `\&lt;` and `&gt;` to be properly embedded in XML.

### More Metadata

Using the `pattern` option with a custom regex, there are more metadata elements which can be captured:

- `ext`
- `designation`
- `name`
- `dbkey`
- `visible`

Each pattern must declare at least either a `designation` or a `name` - the other metadata parts `ext`, `dbkey`, and `visible` are all optional and may also be declared explicitly in via attributes on the `discover_datasets` element (as shown in the above examples).

If no `discover_datasets` element is nested with a tool output - Galaxy will still look for datasets using the named pattern `__default__` which expands to `primary_DATASET_ID_(?P<designation>[^_]+)_(?P<visible>[^_]+)_(?P<ext>[^_]+)(_(?P<dbkey>[^_]+))?`. Many tools use this method as it was the default historically.

For instance consider the following output declaration:

```xml
<outputs>
  <data format="interval" name="output1" metadata_source="input1" />
</outputs>
```

If `$output1.id` (accessible in the tool `command` block) is `546` and the tool produces the files `primary_546_output2_visible_bed` and `primary_546_output3_visible_pdf` in the job's working directory - then after execution is complete these two additional datasets (a bed file and a pdf file) are added to the user's history.

### Further Reading

* [Contrived example tool with demonstration of more patterns and testing of discovered outputs](https://github.com/galaxyproject/galaxy/blob/release_17.01/test/functional/tools/multi_output_configured.xml)
* [Original pull request for discovered dataset enhancements with implementation details](http://bit.ly/gxdiscovereddatasetpr)
* [Implementation of output collection code in galaxy-central](https://github.com/galaxyproject/galaxy/blob/master/lib/galaxy/tools/parameters/output_collect.py)

### Legacy information:

**`force_history_refresh` is deprecated.** In the past, it would be necessary to set the attribute `force_history_refresh` to `True` to force the user's history to fully refresh after the tool run has completed. This functionality is now broken and `force_history_refresh` is ignored by Galaxy. Users now //**`MUST`**// manually refresh their history to see these files. A Trello card used to track the progress on fixing this and eliminating the need to refresh histories in this manner can be found [here](https://trello.com/c/f5Ddv4CS/1993-history-api-determine-history-state-running-from-join-on-running-jobs).

Discovered datasets are available via post job hooks (a deprecated feature) by using the designation - e.g. `__collected_datasets__['primary'][designation]`.

In the past these datasets were typically written to `$__new_file_path__` instead of the working directory. This is not very scalable and `$__new_file_path__` should generally not be used. If you set the option `collect_outputs_from` in `galaxy.ini` ensure `job_working_directory` is listed as an option (if not the only option).
